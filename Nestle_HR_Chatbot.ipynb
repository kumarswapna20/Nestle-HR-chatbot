{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "E5vJOngiYdi7",
   "metadata": {
    "id": "E5vJOngiYdi7"
   },
   "source": [
    "# **Crafting an AI-Powered HR Assistant: A Use Case for Nestle’s HR Policy Documents**\n",
    "\n",
    "# ***Description:***\n",
    "This is a conversational chatbot that responds to user inquiries using PDF document information.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "Mq9A_sITsLiw",
   "metadata": {
    "id": "Mq9A_sITsLiw"
   },
   "source": [
    "# **Steps to Perform:**\n",
    "\n",
    "1. Set up the Environment\n",
    "2. Define a Document Loader\n",
    "3. Create a Document Splitter\n",
    "4. Embed the Text and Save it in Vector Stores\n",
    "5. Create a Retrieval Function\n",
    "6. Run the Chatbot using Gradio UI and answer queries\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "Yz1jxPDoYeyz",
   "metadata": {
    "id": "Yz1jxPDoYeyz"
   },
   "source": [
    "# **Step 1: Set up the Environment**\n",
    "\n",
    "\n",
    "*   Import the necessary libraries.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2357726b",
   "metadata": {
    "id": "2357726b"
   },
   "outputs": [],
   "source": [
    "#Import necessary libraries\n",
    "import os\n",
    "import openai\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d27e8ec1-164c-4d25-b0b2-c56f7171353f",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"OPENAI_API_KEY\"] = \"sk-abcdef1234567890abcdef1234567890abcdef12\" "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "561a1db2",
   "metadata": {
    "id": "561a1db2"
   },
   "source": [
    "# **Step 2: Define a Document Loader**\n",
    "\n",
    "\n",
    "\n",
    "*  Use a document loader like PyPDF to load information from a PDF file.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "431b5328",
   "metadata": {
    "id": "431b5328"
   },
   "outputs": [],
   "source": [
    "#Using PyPDF\n",
    "from langchain.document_loaders import PyPDFLoader\n",
    "\n",
    "Doc_loader = PyPDFLoader(\"HR_policy.pdf\")\n",
    "extracted_text = Doc_loader.load()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "381e6367",
   "metadata": {
    "id": "381e6367"
   },
   "source": [
    "# **Step 3: Create a Document Splitter**\n",
    "\n",
    "\n",
    "*   Break down big pieces of text into smaller parts using text splitters.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "997c60d0",
   "metadata": {
    "id": "997c60d0"
   },
   "outputs": [],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "text_splitter  = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=150,\n",
    "    chunk_overlap=0,\n",
    "    separators=[\"\\n\\n\", \"\\n\", \"(?<=\\. )\", \" \", \"\"]\n",
    ")\n",
    "splitted_text=text_splitter.split_documents(extracted_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "074db8d4",
   "metadata": {
    "id": "074db8d4"
   },
   "source": [
    "# **Step 4: Embed the Text and Save it in Vector Stores**\n",
    "\n",
    "\n",
    "*  Arrange a place to store and organize the text splits to make\n",
    " them searchable.\n",
    "*  Employ OpenAIEmbeddings to create a pretrained model instance, saving the results in a specified directory path.\n",
    "*  FAISS for similarity search in the respective chunks\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0a0bae9d",
   "metadata": {
    "id": "0a0bae9d"
   },
   "outputs": [],
   "source": [
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "embeddings = OpenAIEmbeddings()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b5a3ce63",
   "metadata": {
    "id": "b5a3ce63"
   },
   "outputs": [],
   "source": [
    "from langchain.vectorstores import FAISS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "be3f9f4e",
   "metadata": {
    "id": "be3f9f4e"
   },
   "outputs": [],
   "source": [
    "#persist_directory = \"chroma_vector\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5b380f97",
   "metadata": {
    "id": "5b380f97"
   },
   "outputs": [],
   "source": [
    "vectordb = FAISS.from_documents(\n",
    "    documents=splitted_text,\n",
    "    embedding=embeddings,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00d601da",
   "metadata": {
    "id": "00d601da"
   },
   "source": [
    "# **Step 5: Create a Retrieval Function**\n",
    "\n",
    "\n",
    "*   Retrieve pertinent data from storage based on user input using a retriever.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9222db36",
   "metadata": {
    "id": "9222db36"
   },
   "outputs": [],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "llm = ChatOpenAI(model_name=\"gpt-3.5-turbo\", temperature=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "95613f21",
   "metadata": {
    "id": "95613f21"
   },
   "outputs": [],
   "source": [
    "from langchain.chains import RetrievalQA\n",
    "Retriever_chain = RetrievalQA.from_chain_type(llm,\n",
    "                                       retriever=vectordb.as_retriever(),\n",
    "                                       return_source_documents=False,\n",
    "                                       )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3PgxILTAZOZA",
   "metadata": {
    "id": "3PgxILTAZOZA"
   },
   "source": [
    "# **Step 6: Designing a user-friendly Chatbot interface with Gradio**\n",
    "\n",
    "\n",
    "*   Set up the chatbot, run it and interact with it.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "85368bc8-2090-4b7e-a428-545d3d53d58b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install --upgrade gradio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "dbc054c6-9d4d-4eb8-b9a2-5c9eff05a091",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gradio as gr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "92170267",
   "metadata": {
    "id": "92170267",
    "outputId": "b4011b44-79ba-4467-eb05-9b230fe4b2ae"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/voc/work/.local/lib/python3.10/site-packages/gradio/chat_interface.py:339: UserWarning: The 'tuples' format for chatbot messages is deprecated and will be removed in a future version of Gradio. Please set type='messages' instead, which uses openai-style 'role' and 'content' keys.\n",
      "  self.chatbot = Chatbot(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7869\n",
      "* Running on public URL: https://d195d7811a2d012aa2.gradio.live\n",
      "\n",
      "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"https://d195d7811a2d012aa2.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Define the Gradio chatbot function\n",
    "def chatbot(message, history):\n",
    "    if not message.strip():\n",
    "        return \"Please enter a valid question.\"\n",
    "    try:\n",
    "        response = Retriever_chain.run(message)\n",
    "        return response\n",
    "    except Exception as e:\n",
    "        import traceback\n",
    "        print(\"Error:\", e)\n",
    "        traceback.print_exc()\n",
    "        return f\"⚠️ An error occurred:\\n{str(e)}\"\n",
    "\n",
    "\n",
    "# Create the Gradio Interface\n",
    "chat_ui = gr.ChatInterface(\n",
    "    fn=chatbot,\n",
    "    title=\"HR Policy Assistant\",\n",
    "    description=\"Ask me anything about the HR Policy.\",\n",
    "    theme=\"default\",\n",
    ")\n",
    "\n",
    "# Launch the chatbot \n",
    "chat_ui.launch(share=True)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 [3.10]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
